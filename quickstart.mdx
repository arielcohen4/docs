---
title: "Quickstart"
description: "Start training in under 5 minutes"
---

## Register for an account

First, [register for an account](https://app.getflex.ai/sign-up) to get an API key. New accounts come with $5 to get started.

Once you've registered, go to [settings](https://app.getflex.ai/settings/api-keys) and find your api key:

<Info>
  **Watch our Full Demo Video** You can watch our full demo
  [here](https://www.loom.com/share/f352c51358ba41398b755b6f49f97d5b).
</Info>
<Info>
  **Google Colab** example
  [here](https://colab.research.google.com/drive/1nSFRjrHpbz372h7W-2G7jmTuh_Dhiv9x?authuser=2#scrollTo=RiXPwLmHBOCV).
</Info>

Step 1. Install Flex AI on your OS:

<CodeGroup>

```bash CLI
pip install flex_ai
```

</CodeGroup>

Step 2. Init your flex_ai instance

<CodeGroup>

```bash Python
from flex_ai import FlexAI
client = FlexAI(api_key="xxxxxx")
```

```bash Linux
export FLEX_AI_API_KEY=xxxxxxxxxxxx
```

```bash Windows
set FLEX_AI_API_KEY=xxxxxxxxxxxx
```

</CodeGroup>

## Upload your first Dataset

In FlexAI, there are 3 types of Datasets:

1. instruction
2. chat
3. text

You can read more about them in [Datasets tutorial](https://app.getflex.ai/datasets)
For now we will go with an instruction dataset.
A datasets will have two .jsonl files, one for train and one for eval (evak is optional but recommended)

For example:
create a train.jsonl file:

<CodeGroup>

```bash train-instruction.jsonl
{"instruction": "Some important task with context ?", "output": "Boo" }
{"instruction": "Some important task with context ?", "output": "Boo" }
{"instruction": "Some important task with context ?", "output": "Boo" }
```

```bash train-chat.jsonl
[{"role": "user", "content": "Hi can I train llama model"}, {"role": "assistant", "content": "Sure"}]
[{"role": "user", "content": "Hi can I train llama model"}, {"role": "assistant", "content": "Sure"}]
[{"role": "user", "content": "Hi can I train llama model"}, {"role": "assistant", "content": "Sure"}]
```

```bash train-text.jsonl
{"text": "Some important task with context ? I think I kow" }
{"text": "Some important task with context ? I think I kow" }
{"text": "Some important task with context ? I think I kow" }
```

</CodeGroup>

Now let's create a new dataset

<CodeGroup>

```bash Python
dataset = client.create_dataset("API Dataset New",
                               "instruction/train.jsonl",
                               "instruction/eval.jsonl")
```

```bash CLI
flex_ai datasets create --name "New Dataset" --train-path="train.jsonl" --eval-path="eval.json"
```

</CodeGroup>

You will get back a dataset id to use for run fine tunning

## Fine tune

You view all our models in the [Models Page](https://app.getflex.ai/models)
You can then select a model and dataset and start training.
You can also send fine tune directly from the [Dashboard](https://app.getflex.ai/create)

<CodeGroup>

```bash Python
task = client.create_finetune(name="My Task New",
                       dataset_id=dataset["id"],
                       model="meta-llama/Llama-3.2-1B-Instruct",
                       n_epochs=5,
                       train_with_lora=True,
                       lora_config={"lora_r": 64, "lora_alpha": 8, "lora_dropout": 0.1},
                       n_checkpoints_and_evaluations_per_epoch=1
                       batch_size=4, learning_rate=0.0001, n_checkpoints_and_evaluations_per_epoch=1,
                       save_only_best_checkpoint=False, train_with_lora=True,
                       lora_config={"lora_r": 64, "lora_alpha": 8, "lora_dropout": 0.1}
                      )
```

```bash CLI
flex_ai fine-tuning create \
  --name "Sample Fine-Tuning Task" \
  --dataset-id "62bf5ae8-bbba-438b-9564-36bc902ab393" \
  --model "meta-llama/Llama-3.2-1B-Instruct" \
  --n-epochs 3 \
  --train-with-lora True \
  --n-checkpoints-and-evaluations-per-epoch 2 \
  --lora-r 64 \
  --lora-alpha 16 \
  --lora-dropout 0.1 \
  --batch-size 8 \
  --learning-rate 2e-5 \
  --save-only-best-checkpoint False
```

</CodeGroup>

After you send the fine tuning task, you can view the training metrics on Weights and Biases.
Also you can check the dashboard to see the price estimation for that task and decide if you want to cancel or not.
Checkpoints will be created in parallel to the training with CPU usage.
You can check the training status at [Tasks Page](https://app.getflex.ai/tasks)

## Notebook Example

You can check the notebook example at [Google Colab](https://colab.research.google.com/drive/1nSFRjrHpbz372h7W-2G7jmTuh_Dhiv9x?authuser=2#scrollTo=RiXPwLmHBOCV)

## Full Example

```bash Python
from flex_ai import FlexAI

# Initialize the Flex AI client
client = FlexAI(api_key="your_api_key_here")

# Create a new dataset
dataset = client.create_dataset(
    "API Dataset New",
    "instruction/train.jsonl",
    "instruction/eval.jsonl"
)

# Start a fine-tuning task
task = client.create_finetune(
    name="My Task New",
    dataset_id=dataset["id"],
    model="TinyLlama/TinyLlama-1.1B-step-50K-105b",
    n_epochs=5,
    train_with_lora=True,
    lora_config={
        "lora_r": 64,
        "lora_alpha": 8,
        "lora_dropout": 0.1
    },
    n_checkpoints_and_evaluations_per_epoch=1,
    batch_size=4,
    learning_rate=0.0001,
    save_only_best_checkpoint=True
)

# You can now monitor the task status and results through the Flex AI dashboard
print(f"Fine-tuning task created with ID: {task['id']}")
print("Check the Tasks Page for status updates: https://app.getflex.ai/tasks")

```
