---
title: "Quickstart"
description: "Start training in under 5 minutes"
---

## Register for an account

First, [register for an account](https://app.getflex.ai/auth) to get an API key. New accounts come with $5 to get started.

Once you've registered, go to [settings](https://app.getflex.ai/settings) and find your api key:

<Info>
  **Prerequisite** You should have installed Node.js (version 18.10.0 or
  higher).
</Info>

Step 1. Install Flex AI on your OS:

<CodeGroup>

```bash python
pip install flex_ai
```

</CodeGroup>

Step 2. Init your flex_ai instance

```bash python
client = FlexAI(api_key="API_KEY")
```

### Upload your first Dataset

In FlexAI, there are 3 types of Datasets:

1. instruction
2. chat
3. text

You can read more about them in [Datasets tutorial](https://app.getflex.ai/datasets)
For now we will go with an instruction dataset.
A datasets will have two .jsonl files, one for train and one for eval (evak is optional but recommended)

For example:
create a train.jsonl file:

```bash train.jsonl
{"instruction": "Some important task with context ?", "output": "Boo" }
{"instruction": "Some important task with context ?", "output": "Boo" }
{"instruction": "Some important task with context ?", "output": "Boo" }
```

```bash python
client = FlexAI(api_key="API_KEY")
dataset = client.create_dataset("API Dataset New",
                               "instruction/train.jsonl",
                               "instruction/eval.jsonl",
                                DatasetType.INSTRUCTION)
```

You will get back a dataset id to use for run fine tunning

## Train

You view all our models in the [Models Page](https://app.getflex.ai/models)

<CodeGroup>

```bash python
client.create_finetune(name="My Task New",
                       dataset_id=dataset["id"],
                       model="TinyLlama/TinyLlama-1.1B-step-50K-105b",
                       n_epochs=5,
                       train_with_lora=True,
                       lora_config={"lora_r": 64, "lora_alpha": 8, "lora_dropout": 0.1},
                       n_checkpoints_and_evaluations_per_epoch=1
                      #  batch_size=4, learning_rate=0.0001, n_checkpoints_and_evaluations_per_epoch=1,
                      #  save_only_best_checkpoint=True, train_with_lora=True,
                      #  lora_config={"lora_r": 64, "lora_alpha": 8, "lora_dropout": 0.1},
                      #  early_stopping_config={"patience": 1, "threshold": 0.1}
                       )
```

</CodeGroup>

You view all our models in the [Models Page](https://app.getflex.ai/models)
