# LLM Models Available for Fine-tuning

This table provides an overview of the Large Language Models (LLMs) available for fine-tuning, ordered approximately from most well-known to least familiar. It lists key details for each model, including its name, family, parameter count, context length, and additional features.

| Model Name                                                                                 | Family            | Parameters (B) | Context Length | vLLM Support | LoRA Support |
| ------------------------------------------------------------------------------------------ | ----------------- | -------------- | -------------- | ------------ | ------------ |
| [Meta-Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)       | llama3.1          | 70             | 131,072        | Yes          | Yes          |
| [Meta-Llama-3.1-70B](https://huggingface.co/meta-llama/Llama-2-70b-hf)                     | llama3.1          | 70             | 131,072        | Yes          | Yes          |
| [Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)         | llama3.1          | 8              | 131,072        | Yes          | Yes          |
| [Meta-Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-2-7b-hf)                       | llama3.1          | 8              | 131,072        | Yes          | Yes          |
| [Meta-Llama-3-70B-Instruct](https://ai.meta.com/llama/)                                    | llama3            | 70             | 8,192          | Yes          | Yes          |
| [Meta-Llama-3-70B](https://ai.meta.com/llama/)                                             | llama3            | 70             | 8,192          | Yes          | Yes          |
| [Meta-Llama-3-8B-Instruct](https://ai.meta.com/llama/)                                     | llama3            | 8              | 8,192          | Yes          | Yes          |
| [Meta-Llama-3-8B](https://ai.meta.com/llama/)                                              | llama3            | 8              | 8,192          | Yes          | Yes          |
| [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)  | mixtral           | 46.7           | 32,768         | Yes          | Yes          |
| [Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)      | mistral           | 7.2            | 32,768         | Yes          | Yes          |
| [Mistral-Nemo-Instruct-2407](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)    | mistral           | 12.2           | 128,000        | No           | No           |
| [Mistral-Nemo-Base-2407](https://huggingface.co/mistralai/Mistral-7B-v0.1)                 | mistral           | 12.2           | 128,000        | No           | No           |
| [Gemma-2-27b-it](https://huggingface.co/google/gemma-7b-it)                                | gemma2            | 27             | 8,192          | Yes          | Yes          |
| [Gemma-2-27b](https://huggingface.co/google/gemma-7b)                                      | gemma2            | 27             | 8,192          | Yes          | Yes          |
| [Gemma-2-9b-it](https://huggingface.co/google/gemma-2b-it)                                 | gemma2            | 9              | 8,192          | Yes          | Yes          |
| [Gemma-2-9b](https://huggingface.co/google/gemma-2b)                                       | gemma2            | 9              | 8,192          | Yes          | Yes          |
| [Phi-3-medium-128k-instruct](https://huggingface.co/microsoft/phi-2)                       | phi3              | 14             | 128,000        | Yes          | No           |
| [Phi-3-medium-4k-instruct](https://huggingface.co/microsoft/phi-2)                         | phi3              | 14             | 4,000          | Yes          | No           |
| [Phi-3-small-128k-instruct](https://huggingface.co/microsoft/phi-1_5)                      | phi3              | 7.4            | 128,000        | Yes          | No           |
| [Phi-3-small-8k-instruct](https://huggingface.co/microsoft/phi-1_5)                        | phi3              | 7.4            | 8,000          | Yes          | No           |
| [Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/phi-1)                         | phi3              | 3.8            | 128,000        | Yes          | No           |
| [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/phi-1)                           | phi3              | 3.8            | 4,096          | Yes          | No           |
| [Qwen2-72B-Instruct](https://huggingface.co/Qwen/Qwen1.5-72B-Chat)                         | qwen2             | 72             | 32,768         | Yes          | Yes          |
| [Qwen2-72B](https://huggingface.co/Qwen/Qwen1.5-72B)                                       | qwen2             | 72             | 32,768         | Yes          | Yes          |
| [Qwen2-57B-A14B-Instruct](https://huggingface.co/Qwen/Qwen1.5-14B-Chat)                    | qwen2             | 57             | 32,768         | Yes          | Yes          |
| [Qwen2-57B-A14B](https://huggingface.co/Qwen/Qwen1.5-14B)                                  | qwen2             | 57             | 32,768         | Yes          | Yes          |
| [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen1.5-7B-Chat)                           | qwen2             | 7              | 32,768         | Yes          | Yes          |
| [Qwen2-7B](https://huggingface.co/Qwen/Qwen1.5-7B)                                         | qwen2             | 7              | 32,768         | Yes          | Yes          |
| [Qwen2-1.5B-Instruct](https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat)                       | qwen2             | 1.5            | 32,768         | Yes          | Yes          |
| [Qwen2-1.5B](https://huggingface.co/Qwen/Qwen1.5-1.8B)                                     | qwen2             | 1.5            | 32,768         | Yes          | Yes          |
| [Qwen2-0.5B-Instruct](https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat)                       | qwen2             | 0.5            | 32,768         | Yes          | Yes          |
| [Qwen2-0.5B](https://huggingface.co/Qwen/Qwen1.5-0.5B)                                     | qwen2             | 0.5            | 32,768         | Yes          | Yes          |
| [TinyLlama_v1.1](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)                | tinyllama         | 1.1            | 2,048          | No           | No           |
| [DeepSeek-Coder-V2-Lite-Base](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base) | deepseek-coder-v2 | 16             | 163,840        | No           | No           |
| [InternLM2_5-7B-Chat](https://huggingface.co/internlm/internlm2-7b)                        | internlm2.5       | 7.74           | 1,000,000      | Yes          | No           |
| [InternLM2_5-7B](https://huggingface.co/internlm/internlm2-7b)                             | internlm2.5       | 7.74           | 1,000,000      | Yes          | No           |
| [Jamba-v0.1](https://huggingface.co/ai21labs/Jamba-7B-Instruct)                            | jamba             | 51.6           | 256,000        | Yes          | Yes          |
| [Yi-1.5-34B-Chat](https://huggingface.co/01-ai/Yi-34B-Chat)                                | yi-1.5            | 34.4           | 4,000          | Yes          | Yes          |
| [Yi-1.5-34B](https://huggingface.co/01-ai/Yi-34B)                                          | yi-1.5            | 34.4           | 4,000          | Yes          | Yes          |
| [Yi-1.5-34B-32K](https://huggingface.co/01-ai/Yi-34B-32K)                                  | yi-1.5            | 34.4           | 32,000         | Yes          | Yes          |
| [Yi-1.5-34B-Chat-16K](https://huggingface.co/01-ai/Yi-34B-Chat-16K)                        | yi-1.5            | 34.4           | 16,000         | Yes          | Yes          |
| [Yi-1.5-9B-Chat](https://huggingface.co/01-ai/Yi-9B-Chat)                                  | yi-1.5            | 8.83           | 4,000          | Yes          | Yes          |
| [Yi-1.5-9B](https://huggingface.co/01-ai/Yi-9B)                                            | yi-1.5            | 8.83           | 4,000          | Yes          | Yes          |
| [Yi-1.5-9B-32K](https://huggingface.co/01-ai/Yi-9B-32K)                                    | yi-1.5            | 8.83           | 32,000         | Yes          | Yes          |
| [Yi-1.5-9B-Chat-16K](https://huggingface.co/01-ai/Yi-9B-Chat-16K)                          | yi-1.5            | 8.83           | 16,000         | Yes          | Yes          |
| [Yi-1.5-6B-Chat](https://huggingface.co/01-ai/Yi-6B-Chat)                                  | yi-1.5            | 6              | 4,000          | Yes          | Yes          |
| [Yi-1.5-6B](https://huggingface.co/01-ai/Yi-6B)                                            | yi-1.5            | 6              | 4,000          | Yes          | Yes          |
| [c4ai-command-r-v01](https://huggingface.co/CohereForAI/c4ai-command-r-v01)                | command-r         | 35             | 131,072        | Yes          | No           |

## Notes:

- "vLLM Support" indicates whether the model is compatible with the vLLM (very Large Language Model) inference framework.
- "LoRA Support" indicates if the vLLM support inference the model with multiple LorA Adapters. [Read more](https://docs.vllm.ai/en/latest/models/lora.html)
- Context length is measured in tokens. (The model context can change by the target inference library)
- Parameter count is shown in billions (B).
- Links lead to the model's page on Hugging Face or the official website when available.

This table provides a comprehensive overview of the available models, their sizes, capabilities, and support for various fine-tuning techniques. When choosing a model for fine-tuning, consider factors such as the model size, context length, and support for specific optimization techniques like vLLM and LoRA.
